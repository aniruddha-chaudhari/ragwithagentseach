{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from google import genai\n",
    "from typing import Dict, Any\n",
    "from pydantic import BaseModel\n",
    "\n",
    "api_key = os.getenv(\"GEMINI_API_KEY\", \"AIzaSyD4lR1WQ1yaZumSFtMVTG_0Y8d0oRy1XhA\")\n",
    "client = genai.Client(api_key=api_key)\n",
    "\n",
    "class GoogleSearchIntentResult(BaseModel):\n",
    "    requires_search: bool\n",
    "\n",
    "\n",
    "\n",
    "def detect_google_search_intent(query: str) -> bool:\n",
    "    \"\"\"\n",
    "    Determines if the user's query requires internet access to answer properly.\n",
    "    \n",
    "    Args:\n",
    "        query (str): The user's query\n",
    "        \n",
    "    Returns:\n",
    "        bool: True if the query requires internet access, False otherwise\n",
    "    \"\"\"\n",
    "   \n",
    "    prompt = f\"\"\"You are an expert at determining when a query requires up-to-date information from the internet.\n",
    "    \n",
    "    Your task is to:\n",
    "    1. Analyze the following user query\n",
    "    2. Determine if an LLM without internet access can provide a satisfactory answer\n",
    "    3. If the query likely needs internet access (e.g., current events, specific data, recent information), return: {{\"requires_search\": true}}\n",
    "    4. If the query can be answered without internet access (e.g., general knowledge, coding help), return: {{\"requires_search\": false}}\n",
    "    \n",
    "    Examples requiring internet:\n",
    "    - Current news or events\n",
    "    - Recent statistics or data\n",
    "    - Real-time information (weather, stocks)\n",
    "    - Specific factual lookups that aren't common knowledge\n",
    "    - Information that changes frequently\n",
    "    \n",
    "    Return ONLY the JSON object without any additional text.\n",
    "    \n",
    "    User query: {query}\n",
    "    \"\"\"\n",
    "     \n",
    "    try:\n",
    "        \n",
    "        response = client.models.generate_content(\n",
    "            model='gemini-2.0-flash',\n",
    "            contents=prompt,\n",
    "            config={\n",
    "                'response_mime_type': 'application/json',\n",
    "                'response_schema': GoogleSearchIntentResult,\n",
    "            },\n",
    "        )\n",
    "        \n",
    "        result = response.parsed\n",
    "        return result.requires_search\n",
    "    except Exception as e:\n",
    "        print(f\"Error detecting search intent: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: \n",
      "Marks: 78\n",
      "Remarks: ['Clear and Concise Introduction', 'Well-Structured Theory Section', 'Step-by-Step Algorithm Implementation', 'Includes Advantages and Disadvantages', 'Applications Section', 'Code Implementation', 'Output Displayed', 'Conclusion']\n",
      "Suggestions: ['Depth of Theoretical Explanation', 'Discussion of Parameters', 'Visualizations', 'More Detailed Analysis of Output', 'Comparisons with Other Algorithms', 'Code Comments', 'Introduction']\n",
      "Errors: ['Minor Formatting', 'Grammar/Typos: \"sollution\" should be \"solution.\"']\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from google import genai\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Dict, Any, Tuple, TypedDict, Union\n",
    "\n",
    "class PaperCheckResult(BaseModel):\n",
    "    Name: str = Field(\"\", description=\"Paper taker's name or anything that hels identify the paper taker\")\n",
    "    marks: int\n",
    "    remarks: List[str]\n",
    "    suggestions: List[str]\n",
    "    errors: List[str]\n",
    "\n",
    "class ProcessResult(TypedDict):\n",
    "    success: bool\n",
    "    error: str | None\n",
    "    results: List[Dict[str, Any]] | None\n",
    "\n",
    "def prepare_document(file_path: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Prepares the document and gets initial response\n",
    "    Returns: Dictionary with raw response\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Initialize the Google AI client\n",
    "        client = genai.Client(api_key=\"AIzaSyD4lR1WQ1yaZumSFtMVTG_0Y8d0oRy1XhA\")\n",
    "        \n",
    "        # Upload the file\n",
    "        uploaded_file = client.files.upload(file=file_path)\n",
    "        \n",
    "        # First prompt for general analysis\n",
    "        initial_prompt = \"\"\"\n",
    "        Analyze this academic paper and provide feedback. Include:\n",
    "        1. Overall quality score (0-100)\n",
    "        2. Positive aspects of the paper\n",
    "        3. Areas that need improvement\n",
    "        4. Any errors or problems found\n",
    "        \"\"\"\n",
    "        \n",
    "        # Get initial response\n",
    "        initial_response = client.models.generate_content(\n",
    "            model=\"gemini-2.0-flash\",\n",
    "            contents=[uploaded_file, initial_prompt]\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"success\": True, \n",
    "            \"uploaded_file\": uploaded_file,\n",
    "            \"initial_response\": initial_response.text\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\"success\": False, \"error\": f\"Error preparing document: {str(e)}\"}\n",
    "\n",
    "def analyze_document(initial_result: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Takes initial response and converts it to structured format\n",
    "    Returns: Dictionary with structured results\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not initial_result[\"success\"]:\n",
    "            return initial_result\n",
    "            \n",
    "        client = genai.Client(api_key=\"AIzaSyD4lR1WQ1yaZumSFtMVTG_0Y8d0oRy1XhA\")\n",
    "        \n",
    "        structure_prompt = f\"\"\"\n",
    "        Convert the following feedback into a structured JSON format:\n",
    "\n",
    "        {initial_result['initial_response']}\n",
    "\n",
    "        The JSON should have this structure:\n",
    "        {{  \"Name\": \"Roll No or name of the paper taker if found, otherwise empty string\",\n",
    "            \"marks\": integer (0-100) it should depend on how good remarks are and how many errors there are,\n",
    "            \"remarks\": [list of positive comments],\n",
    "            \"suggestions\": [list of improvement areas],\n",
    "            \"errors\": [list of problems found]\n",
    "        }}\n",
    "\n",
    "        IMPORTANT: Ensure marks is a valid integer between 0 and 100. If no specific score is found, use 0.\n",
    "        Ensure all arrays are empty lists [] instead of null when there are no items.\n",
    "        Ensure Name is an empty string \"\" if no name is found.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Get structured response\n",
    "        structured_response = client.models.generate_content(\n",
    "            model=\"gemini-2.0-flash\",\n",
    "            contents=structure_prompt,\n",
    "            config={\n",
    "                'response_mime_type': 'application/json'\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # Parse the response safely\n",
    "        try:\n",
    "            # Clean the response text to ensure it's valid JSON\n",
    "            response_text = structured_response.text.strip()\n",
    "            if response_text.startswith(\"```json\"):\n",
    "                response_text = response_text[7:]\n",
    "            if response_text.endswith(\"```\"):\n",
    "                response_text = response_text[:-3]\n",
    "            response_text = response_text.strip()\n",
    "            \n",
    "            data = json.loads(response_text)\n",
    "            \n",
    "            # Ensure data structure is correct and all fields are valid\n",
    "            if isinstance(data, dict):\n",
    "                data[\"marks\"] = int(data.get(\"marks\", 0))  # Convert to int, default to 0\n",
    "                data[\"Name\"] = str(data.get(\"Name\", \"\"))  # Convert to string, default to empty string\n",
    "                data[\"remarks\"] = list(data.get(\"remarks\", []))\n",
    "                data[\"suggestions\"] = list(data.get(\"suggestions\", []))\n",
    "                data[\"errors\"] = list(data.get(\"errors\", []))\n",
    "            \n",
    "        except json.JSONDecodeError as e:\n",
    "            return {\"success\": False, \"error\": f\"Failed to parse AI response: {str(e)}\"}\n",
    "        except (ValueError, TypeError) as e:\n",
    "            return {\"success\": False, \"error\": f\"Invalid value conversion: {str(e)}\"}\n",
    "        \n",
    "        if not isinstance(data, list):\n",
    "            data = [data]\n",
    "            \n",
    "        results = [PaperCheckResult(**item) for item in data]\n",
    "        final_results = {\"success\": True, \"results\": [r.model_dump() for r in results]}\n",
    "        return final_results\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\"success\": False, \"error\": str(e)}\n",
    "\n",
    "def process_document(file_path: str) -> ProcessResult:\n",
    "    \"\"\"\n",
    "    Main function that coordinates the document processing\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # First get raw analysis\n",
    "        initial_result = prepare_document(file_path)\n",
    "        if not initial_result[\"success\"]:\n",
    "            return {\"success\": False, \"error\": initial_result[\"error\"], \"results\": None}\n",
    "            \n",
    "        # Then convert to structured format\n",
    "        result = analyze_document(initial_result)\n",
    "        if not result[\"success\"]:\n",
    "            return {\"success\": False, \"error\": result[\"error\"], \"results\": None}\n",
    "            \n",
    "        return {\"success\": True, \"error\": None, \"results\": result[\"results\"]}\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\"success\": False, \"error\": str(e), \"results\": None}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    file_path = 'F:/Aniruddha/code/webdev/PROJECTS/teacherassistant/ai5.pdf'\n",
    "    result = process_document(file_path)\n",
    "    \n",
    "    if result[\"success\"]:\n",
    "        for paper_result in result[\"results\"]:\n",
    "            print(f\"Name: {paper_result['Name']}\")\n",
    "            print(f\"Marks: {paper_result['marks']}\")\n",
    "            print(f\"Remarks: {paper_result['remarks']}\")\n",
    "            print(f\"Suggestions: {paper_result['suggestions']}\")\n",
    "            print(f\"Errors: {paper_result['errors']}\")\n",
    "            print(\"-\" * 50)\n",
    "    else:\n",
    "        print(\"Error:\", result[\"error\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: File not found at --f=\"c:\\Users\\Aniruddha Chaudhari\\AppData\\Roaming\\jupyter\\runtime\\kernel-v361c19affca1141d34862a6288978fe1575b341fb.json\"\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Aniruddha Chaudhari\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3585: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "from datetime import datetime\n",
    "from typing import List, Tuple, Optional\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import streamlit as st\n",
    "import bs4\n",
    "from langchain_community.document_loaders import PyPDFLoader, WebBaseLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document\n",
    "from google import genai\n",
    "\n",
    "def prepare_document(file_path: str) -> List[Document]:\n",
    "    \"\"\"\n",
    "    Processes any document type using Gemini API and returns it in a format\n",
    "    compatible with the vector storage system.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Path to the document file\n",
    "        \n",
    "    Returns:\n",
    "        List[Document]: List containing the processed document\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Handle API key retrieval for both Streamlit and FastAPI environments\n",
    "        if 'st' in globals() and hasattr(st, 'session_state'):\n",
    "            # Streamlit environment\n",
    "            api_key = st.session_state.get(\"google_api_key\", os.getenv(\"GEMINI_API_KEY\", \"\"))\n",
    "        else:\n",
    "            # FastAPI environment - get from environment only\n",
    "            api_key = os.getenv(\"GEMINI_API_KEY\", \"\")\n",
    "            \n",
    "        client = genai.Client(api_key=api_key)\n",
    "        \n",
    "        # Determine appropriate prompt based on file type\n",
    "        file_extension = os.path.splitext(file_path)[1].lower()\n",
    "        \n",
    "        # Upload the file directly without opening it\n",
    "        # The files.upload method will handle opening the file\n",
    "        uploaded_file = client.files.upload(file=file_path)\n",
    "        \n",
    "        if file_extension in ['.png', '.jpg', '.jpeg', '.gif', '.webp']:\n",
    "            prompt = \"\"\"\n",
    "            Please analyze and describe this image in detail. Include:\n",
    "            1. Type of content and main subject\n",
    "            2. Key information or features\n",
    "            3. Visual elements and their significance\n",
    "            4. Any text present in the image\n",
    "            5. Overall meaning and context\n",
    "            \"\"\"\n",
    "            source_type = \"image\"\n",
    "        else:\n",
    "            prompt = \"\"\"\n",
    "            Please analyze and summarize this document in detail. Include:\n",
    "            1. Type of content and main subject\n",
    "            2. Key information or facts\n",
    "            3. Structure and organization\n",
    "            4. Main arguments or points\n",
    "            5. Overall context and significance\n",
    "            \"\"\"\n",
    "            source_type = \"document\"\n",
    "        \n",
    "        # Generate content\n",
    "        response = client.models.generate_content(\n",
    "            model=\"gemini-2.0-flash\",\n",
    "            contents=[uploaded_file, prompt],\n",
    "        )\n",
    "        \n",
    "        content = response.text\n",
    "        print(f\"Generated content length: {len(content)}\")\n",
    "        \n",
    "        # Create a Document object\n",
    "        doc = Document(\n",
    "            page_content=content,\n",
    "            metadata={\n",
    "                \"source_type\": source_type,\n",
    "                \"file_name\": os.path.basename(file_path),\n",
    "                \"timestamp\": datetime.now().isoformat()\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        # Apply text splitting\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=1000,\n",
    "            chunk_overlap=200\n",
    "        )\n",
    "        chunks = text_splitter.split_documents([doc])\n",
    "        print(f\"Number of document chunks: {len(chunks)}\")\n",
    "        \n",
    "        return chunks\n",
    "        \n",
    "    except Exception as e:\n",
    "        if 'st' in globals() and hasattr(st, 'session_state'):\n",
    "            # Streamlit environment\n",
    "            st.error(f\"📄 Document processing error: {str(e)}\")\n",
    "        else:\n",
    "            # FastAPI environment - print to console\n",
    "            print(f\"Document processing error: {str(e)}\")\n",
    "        # Re-raise the exception with a clearer message\n",
    "        raise ValueError(f\"No text content could be extracted from the file: {str(e)}\")\n",
    "\n",
    "# Adding direct testing capability when run as main\n",
    "# ...existing code...\n",
    "\n",
    "# Adding direct testing capability when run as main\n",
    "if __name__ == \"__main__\":\n",
    "    # ======= MANUALLY SET YOUR FILE PATH HERE =======\n",
    "    manual_file_path = \"F:/Aniruddha/code/webdev/PROJECTS/teacherassistant/your_document.pdf\"\n",
    "    # ===============================================\n",
    "    \n",
    "    # Use manually specified path by default\n",
    "    test_file_path = manual_file_path\n",
    "    \n",
    "    # Command-line argument support (optional, can be removed if not needed)\n",
    "    if len(sys.argv) > 1:\n",
    "        test_file_path = sys.argv[1]\n",
    "    \n",
    "    # Check if file exists\n",
    "    if not os.path.exists(test_file_path):\n",
    "        print(f\"Error: File not found at {test_file_path}\")\n",
    "        sys.exit(1)\n",
    "        \n",
    "    print(f\"Processing document: {test_file_path}\")\n",
    "    \n",
    "    try:\n",
    "        # Process the document\n",
    "        chunks = prepare_document(test_file_path)\n",
    "        \n",
    "        # Display results\n",
    "        print(f\"\\nSuccessfully processed document into {len(chunks)} chunks\")\n",
    "        print(\"\\nFirst chunk content preview:\")\n",
    "        if chunks:\n",
    "            print(f\"{chunks[0].page_content[:200]}...\")\n",
    "            print(\"\\nMetadata:\")\n",
    "            for key, value in chunks[0].metadata.items():\n",
    "                print(f\"  {key}: {value}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nError processing document: {str(e)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
